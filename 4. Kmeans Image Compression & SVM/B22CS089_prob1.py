# -*- coding: utf-8 -*-
"""B22CS089_prob1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-3pdL7hACKO1bwyPNCTrkqfCowZxfOgx
"""

from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

# opening image
image_path = 'test.png'
image = Image.open(image_path)

#convert
image = image.convert('RGB')

width, height = image.size
print(image.size)
print(width)
print(height)
rgb_values = []
for y in range(height):
    for x in range(width):
        r, g, b = image.getpixel((x, y))
        rgb_values.append((r, g, b))

# extract rgb array

rgb_array = np.array(rgb_values)
print(rgb_array.shape)

# Calculate the frequencies of each color in the actual image
actual_colors, actual_counts = np.unique(rgb_array, axis=0, return_counts=True)

# Sort colors based on their frequencies and select the top 5
sorted_indices = np.argsort(actual_counts)[::-1][:5]
top_colors = actual_colors[sorted_indices]
top_counts = actual_counts[sorted_indices]

# Plot pie chart for top 5 colors in the actual image
plt.figure(figsize=(8, 4))
plt.pie(top_counts, labels=['Color {}'.format(i+1) for i in range(len(top_colors))], autopct='%1.1f%%')
plt.title('Top 5 Most Used Colors - Actual Image')

plt.tight_layout()
plt.show()

print(rgb_array[:,0])

import pandas as pd
import matplotlib.pyplot as plt
# as a panda dataframe

df = pd.DataFrame(rgb_array, columns=['red', 'green', 'blue'])
print(df)

print(df.iloc[:,0].mean())

print(df['red'].mean())

#compute centroid function
def computeCentroid(data):
    centroid = []
    for i in data:
        mean = data[i].mean()
        centroid.append(mean)

    return centroid

cnt = computeCentroid(df)
print(cnt)

# from sklearn.preprocessing import MinMaxScaler
# scaler = MinMaxScaler()
# scaler.fit(rgb_array)
# scaled_data = scaler.transform(rgb_array)
# print(scaled_data)

import random

# creating important functions

def assign_clusters(X, centroids):
    cluster_group = []
    distances = []

    distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)
    classifications = np.argmin(distances, axis=1)


    return classifications


def move_centroids(X,cluster_group):
    new_centroids = []

    cluster_type = np.unique(cluster_group)

    for type in cluster_type:
        new_centroids.append(X[cluster_group == type].mean(axis=0))

    return np.array(new_centroids)

# mykmeans functions
def mykmeans(X, n_clusters, max_itr):
    centroids = X[random.sample(range(0,X.shape[0]),n_clusters)]
    # print(centroids)
    for i in range(max_itr):
        # assign clusters
        cluster_group = assign_clusters(X, centroids)
        old_centroids = centroids

        # move centroids
        centroids = move_centroids(X,cluster_group)

        # check finish
        if (old_centroids == centroids).all():
            print('K-means done')
            break

    return cluster_group,centroids

y_pred,cluster_centroids = mykmeans(rgb_array,6,100)

y_pred.shape

print(np.unique(y_pred))

print(cluster_centroids)

rgb_data = rgb_array.copy()

for i in np.unique(y_pred):
    rgb_data[y_pred == i] = cluster_centroids[i]

rgb_data[:10]

import matplotlib.pyplot as plt



def show_comp_img(rgb_array):
    # Open the image
    image = Image.open("test.png")

    # Convert the image to a numpy array
    image_array = np.array(image)
    height, width, _ = image_array.shape


    image_array[:] = rgb_array.reshape(height, width, 3)

    updated_image = Image.fromarray(image_array)

    # Save the updated image
    updated_image.save("updated_image.png")

    # Open the images
    image1 = Image.open("test.png")
    image2 = Image.open("updated_image.png")

    # Create a new blank image with twice the width of the original images
    new_image = Image.new('RGB', (width * 2, height))

    # Paste the first image on the left side of the new image
    new_image.paste(image1, (0, 0))

    # Paste the second image on the right side of the new image
    new_image.paste(image2, (width, 0))

    # Display the new image
    plt.imshow(new_image)
    plt.axis('off')
    plt.show()

rgb_data.shape

rgb_data

k_vals = [1,2,3,4,5,6,7,8,9,10]

#clustering through mykmeans

for i in k_vals:
    y_pred,cluster_centroids = mykmeans(rgb_array,i,250)
    rgb_data = rgb_array.copy()
    for j in np.unique(y_pred):
        rgb_data[y_pred == j] = cluster_centroids[j]
    print(f'value of k is {i}')
    show_comp_img(rgb_data)
    print(rgb_data)

from collections import Counter
import matplotlib.pyplot as plt

k_vals = [1,2,3,4,5,6,7,8,9,10]

#doing the same thing with top 5 color piechart

for k in k_vals:

    y_pred, cluster_centroids = mykmeans(rgb_array, k, 250)


    compressed_data = rgb_array.copy()
    for j in np.unique(y_pred):
        compressed_data[y_pred == j] = cluster_centroids[j]

    # Calculate the frequencies of each color in the compressed image
    compressed_colors, compressed_counts = np.unique(compressed_data, axis=0, return_counts=True)

    # Sort colors based on their frequencies and select the top 5
    sorted_indices = np.argsort(compressed_counts)[::-1][:5]
    top_colors = compressed_colors[sorted_indices]
    top_counts = compressed_counts[sorted_indices]

    # Plot pie chart for top 5 colors in the compressed image
    plt.figure(figsize=(6, 6))
    plt.pie(top_counts, labels=['Color {}'.format(i+1) for i in range(len(top_colors))], autopct='%1.1f%%')
    plt.title(f'Top 5 Most Used Colors - Compressed Image (K={k})')
    plt.show()

    # Display the compressed image
    show_comp_img(compressed_data)

# elbow method to check the number of clusters
# distortion vs number of clusters
# through sklearn inertia

from sklearn.cluster import KMeans
distortions = []
for i in range(1,10):
  km = KMeans(n_clusters =i, init='k-means++',n_init=10,max_iter=300,random_state=0)
  km.fit(rgb_array)
  distortions.append(km.inertia_)
plt.plot(range(1,10),distortions,marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('Distortion')
plt.tight_layout()
plt.show()

# k=5 through elbow method

# Perform KMeans clustering
k = 5
kmeans = KMeans(n_clusters=k,n_init=10, random_state=0,max_iter=300)
labels = kmeans.fit_predict(rgb_array)
centroids = kmeans.cluster_centers_.astype(np.uint8)
compressed_data = centroids[labels]
print(compressed_data.shape)
# Reshape the compressed data back to the image shape
compressed_image = compressed_data.reshape((512, 512,3))
print(compressed_image.shape)
# Display the original and compressed images side by side
plt.figure(figsize=(5, 5))

# Original image
plt.subplot(1, 2, 1)
plt.imshow(image)
plt.axis('off')
plt.title('Original Image')

# Compressed image
plt.subplot(1, 2, 2)
plt.imshow(compressed_image)
plt.axis('off')
plt.title(f'Compressed Image with K={k}')

plt.tight_layout()
plt.show()

from collections import Counter

# Get the colors and their frequencies for the compressed image
compressed_colors, compressed_counts = np.unique(compressed_data, axis=0, return_counts=True)

# Plot pie chart for compressed image
plt.figure(figsize=(5, 5))
plt.pie(compressed_counts, labels=['Color {}'.format(i+1) for i in range(len(compressed_colors))], autopct='%1.1f%%')
plt.title('Most Used Colors - Compressed Image')

plt.show()

from sklearn.cluster import KMeans
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

def spatial_distance(p1, p2):
    # Euclidean distance between two spatial points
    return np.sqrt(np.sum((p1 - p2)**2))

def spatially_weighted_distance(p1, p2, spatial_weight=10):
    # Weighted distance metric incorporating both color and spatial proximity
    color_distance = np.sqrt(np.sum((p1[:3] - p2[:3])**2))
    spatial_dist = spatial_weight * spatial_distance(p1[3:], p2[3:])
    return color_distance + spatial_dist

# Load the image
image_path = 'test.png'
image = Image.open(image_path)
image = image.convert('RGB')
width, height = image.size

# Convert the image into a 2D array of pixels
rgb_values = []
for y in range(height):
    for x in range(width):
        r, g, b = image.getpixel((x, y))
        rgb_values.append([r, g, b, x, y])  # Adding spatial coordinates

rgb_array = np.array(rgb_values)

# Perform KMeans clustering with dynamic spatial weight
k = 15 # Number of clusters
kmeans = KMeans(n_clusters=k, random_state=0, n_init=10, max_iter=300)

# Custom distance function for KMeans
def custom_distance(x, y):
    # Calculate spatial weight dynamically based on spatial distance
    spatial_dist = spatial_distance(x[3:], y[3:])
    spatial_weight = 1 / (spatial_dist + 1)  # Inverse of spatial distance
    return spatially_weighted_distance(x, y, spatial_weight=spatial_weight)

# Modify KMeans algorithm to use custom distance function
kmeans._algorithm = "full"  # Use the "full" algorithm to support custom distance function
kmeans.init = 'random'  # Use random initialization

# Set the custom distance function
kmeans._distance_func = custom_distance.__get__(kmeans)

# Fit the model and get labels
labels = kmeans.fit_predict(rgb_array)
centroids = kmeans.cluster_centers_.astype(np.uint8)

# Replace pixel values with cluster centroids
compressed_data = centroids[labels]

# Reshape the compressed data back to the image shape
compressed_image = compressed_data[:, :3].reshape((height, width, 3))

# Display the compressed image
plt.figure(figsize=(5,5))
plt.imshow(compressed_image)
plt.axis('off')
plt.title(f'Compressed Image with K={k} (Spatial Coherence)')
plt.show()