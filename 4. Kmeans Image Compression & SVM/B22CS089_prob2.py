# -*- coding: utf-8 -*-
"""B22CS089_prob2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g-J9Ibuz3wOQTAw30Jz5deMEu_Abxwnh
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import LinearSVC
from sklearn.datasets import make_moons
from sklearn import datasets, svm
from sklearn.inspection import DecisionBoundaryDisplay
from sklearn.model_selection import GridSearchCV
import seaborn as sns
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
#importing necessary libraries

"""TASK- 1(a)"""

#load the iris dataset

iris = datasets.load_iris(as_frame=True)

#focusing only on the petal length and petal width features

X = iris.data[['petal length (cm)', 'petal width (cm)']]
y = iris.target

# selecting only two classes, ‘setosa’ and ‘versicolor’ for binary classification
# As first 100 samples either correspond to setsoa or versicolor

X = X.iloc[:100]
y = y[:100]

# normalize the the features

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# split the dataset into train and test

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

print(X_train)

print(X_test)

y_train

"""TASK- 1(b)"""

# Fit the model
clf = LinearSVC(random_state=42)
clf.fit(X_train, y_train)

# Calculating decision boundary
w = clf.coef_[0]
a = -w[0] / w[1]
xx = np.linspace(-2, 2)
yy = a * xx - (clf.intercept_[0]) / w[1]

# Plot the decision boundary of the model on the train data
plt.figure(figsize=(16, 6))

plt.subplot(1, 2, 1)
sns.set(style="whitegrid", font_scale=1.2)
plt.plot(xx, yy, 'k-', label='Decision Boundary')
sns.scatterplot(x=X_train[:, 0], y=X_train[:, 1], hue=y_train, palette='viridis', legend='full')
plt.xlabel('Petal Length (cm)')
plt.ylabel('Petal Width (cm)')
plt.title('Decision Boundary of LinearSVC on Train Data')
plt.legend(loc='lower right')

# Plot the decision boundary of the model on the test data
plt.subplot(1, 2, 2)
sns.set(style="whitegrid", font_scale=1.2)
plt.plot(xx, yy, 'k-', label='Decision Boundary')
sns.scatterplot(x=X_test[:, 0], y=X_test[:, 1], hue=y_test, palette='viridis', legend='full')
plt.xlabel('Petal Length (cm)')
plt.ylabel('Petal Width (cm)')
plt.title('Decision Boundary of LinearSVC on Test Data')
plt.legend(loc='lower right')

# using tight layout to evade the overlapping problem

plt.tight_layout()
plt.show()

# Predict on test data
y_test_pred = clf.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_test_pred)
print("Accuracy:", accuracy)

# checking if the model is underfitting or overfitting

# Predict on train data

y_pred_train = clf.predict(X_train)

# Calculate accuracy
accuracy_train = accuracy_score(y_train, y_pred_train)
print("Training Accuracy:", accuracy_train)

# Generate classification report
report = classification_report(y_test, y_test_pred)
print("Classification Report:")
print(report)


# Generate confusion matrix
cm = confusion_matrix(y_test, y_test_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

"""TASK- 2(a)"""

# Generate a synthetic dataset using the make moons() function

X, y = make_moons(n_samples=500, noise=0.05, random_state=42)

print(X)

print(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(y_train.shape)

"""TASK- 2(b)"""

C = 1.0  # SVM regularization parameter

# implement three different kernels

models = (
    svm.SVC(kernel="linear", C=C),
    svm.SVC(kernel="rbf", gamma=0.67, C=C),
    svm.SVC(kernel="poly", degree=5, gamma="auto", C=C),
)

models = (clf.fit(X_train_scaled, y_train) for clf in models)

# titles for the plots
titles = (
    "SVC with linear kernel",
    "SVC with RBF kernel",
    "SVC with polynomial kernel",
)
# evaluate models
for clf, title in zip(models, titles):
    clf.fit(X_train_scaled, y_train)
    y_pred = clf.predict(X_test_scaled)

    # Calculate accuracy
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Accuracy for {title}: {accuracy:.2f}")

    # checking if the model is underfitting or overfitting

    # Predict on train data

    y_pred_train = clf.predict(X_train_scaled)

    # Calculate accuracy
    accuracy_train = accuracy_score(y_train, y_pred_train)
    print("Training Accuracy:", accuracy_train)

    # Generate classification report
    report = classification_report(y_test, y_pred)
    print(f"Classification Report for {title}:\n{report}")

    # Generate confusion matrix
    cm = confusion_matrix(y_test, y_pred)

    # Plot confusion matrix
    plt.figure(figsize=(8, 6))
    sns.set(font_scale=1.2)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title(f'Confusion Matrix for {title}')
    plt.show()

models = (
    svm.SVC(kernel="linear", C=C),
    svm.SVC(kernel="rbf", gamma=0.67, C=C),
    svm.SVC(kernel="poly", degree=5, gamma="auto", C=C),
)

models = (clf.fit(X_train_scaled, y_train) for clf in models)

# title for the plots
titles = (
    "SVC with linear kernel",
    "SVC with RBF kernel",
    "SVC with polynomial kernel",
)
# Set the style and font
sns.set_style("whitegrid")
sns.set_context("talk", font_scale=1.2)

# Create subplots with adjusted figsize
fig, sub = plt.subplots(1, 3, figsize=(24, 8))

# Plot decision boundary for each kernel
for clf, title, ax in zip(models, titles, sub.flatten()):
    disp = DecisionBoundaryDisplay.from_estimator(
        clf,
        X_train_scaled,
        response_method="predict",
        cmap=plt.cm.coolwarm,
        alpha=0.8,
        ax=ax,
    )
    sns.scatterplot(x=X_train_scaled[:, 0], y=X_train_scaled[:, 1], hue=y_train, ax=ax)
    ax.set_xticks(())
    ax.set_yticks(())
    ax.set_title(title)

plt.tight_layout()
plt.show()

"""TASK-2(c)"""

#focusing on only RBF
# performing hyperparameter tuning
# grid search for gamma and c values

param_grid = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.1, 0.01, 0.001, 0.0001]}

grid_search = GridSearchCV(svm.SVC(kernel='rbf', random_state=42), param_grid, cv=5)
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
best_C = best_params['C']
best_gamma = best_params['gamma']
print(best_params)

"""TASK-2(d)"""

# Plotting the decision boundary for the RBF kernel SVM with the best Hyperparameters
# Set the style and font
sns.set_style("whitegrid")
sns.set_context("talk", font_scale=1.2)

# best hyperparameters
C = 100
gamma = 0.1


model = svm.SVC(kernel="rbf", gamma=gamma, C=C)

# Fit the model
model.fit(X_train_scaled, y_train)

fig, sub = plt.subplots(1, 1, figsize=(12, 8))

# Plot decision boundary
disp = DecisionBoundaryDisplay.from_estimator(
    model,
    X_train_scaled,
    response_method="predict",
    cmap=plt.cm.coolwarm,
    alpha=0.8,
    ax=sub,
)
sns.scatterplot(x=X_train_scaled[:, 0], y=X_train_scaled[:, 1], hue=y_train, palette='coolwarm', ax=sub)
sub.set_xticks(())
sub.set_yticks(())
sub.set_title("SVC with RBF kernel")

plt.show()

# Predict on test data
y_pred = model.predict(X_test_scaled)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Generate classification report
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

# Generate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

# checking if the model is underfitting or overfitting

# Predict on train data

y_pred = model.predict(X_train_scaled)

# Calculate accuracy
accuracy = accuracy_score(y_train, y_pred)
print("Training Accuracy:", accuracy)